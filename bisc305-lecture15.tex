% Copyright 2007 by Till Tantau
%
% This file may be distributed and/or modified
%
% 1. under the LaTeX Project Public License and/or
% 2. under the GNU Public License.
%
% See the file doc/licenses/LICENSE for more details.


\lecture[15]{the Wilcoxon--Mann--Whitney test}{lecture-text}

\subtitle{and nonparametric testing}

\date{24 March 2015}

% pp. 282-293


\begin{document}

\begin{frame}
  \maketitle
\end{frame}


\section*{Overview}

\begin{frame}{So far, we know}
  \begin{enumerate}
    \item How to use the $t$-test to compare means of two populations,
    \item \ldots which uses the difference in sample means as a test statistic.
    \item The $t$-test requires the sampling distributions of the sample means to be approximately Normal.
    \item The null hypothesis describes the model to use to calculate the $P$-value.
  \end{enumerate}
\end{frame}

\begin{frame}\frametitle<presentation>{Outline}
  \tableofcontents
\end{frame}



\section{The Wilcoxon--Mann--Whitney test}

\subsection{Distribution--free tests}

\begin{frame}{Distribution--free tests}
  \begin{block}{Distribution--free (or, nonparametric)}
    means that the validity of the test does not depend on the specific shape of population distributions.
  \end{block}

    \vspace{2em}

    \structure{Goal:} compare the ``central tendency'' in two datasets,
    in a distribution-free way.

    \vspace{3em}

    \structure{Note:} The Central Limit Theorem implies that the $t$-test is not very sensitive to the population distribution, with large sample sizes.  That doesn't count as ``distribution--free''.

\end{frame}

\subsection{The Wilcoxon--Mann--Whitney test statistic}

\begin{frame}{The test statistic}

    We have two datasets, % $y^1_1, y^1_2, \ldots, y^1_n$, and $y^2_1, y^2_2, \ldots, y^2_m$ -- $n$ 
    $n$ observations in the first and $n'$ in the second.

  \begin{block}{Definition}
    $K_1$ is the number of comparisons between the observations from the first and the second dataset for which the observation from the first is larger (with $1/2$ for ties). 
    $K_2$ is the number for which the observation from the second is larger.
    The Wilcoxon--Mann--Whitney test statistic, $U_s$, 
    is the larger of $K_1$ and $K_2$.
  \end{block}


    \vspace{1em}

    Method for computation:
    \begin{enumerate}
      \item Order each sample.
      \item For each observation, write down how many in the other dataset are smaller.
      \item $K_1$ is the sum of those numbers for the first dataset; $K_2$ is the sum for the second.
      \item $U_s$ is the larger of $K_1$ and $K_2$.
    \end{enumerate}

    \vspace{1em}

    Note that $K_1 + K_2 = n n'$.

\end{frame}

%%%%%%
\begin{frame}{Example: soil respiration}

  Soil cores from two locations, ``gap'' and ``growth'';
  measured amount of CO${}_2$ released.

  \begin{center}
  \begin{tabular}{l|p{2.5in}}
    growth & 17 \hspace{.25em} 20 \hspace{.25em} 170 \hspace{.25em} 315 \hspace{.25em} 22 \hspace{.25em} 190 \hspace{.25em} 64 \\
    \hline
    gap & 22 \hspace{.25em} 29 \hspace{.25em} 13 \hspace{.25em} 16 \hspace{.25em} 15 \hspace{.25em} 18 \hspace{.25em} 14 \hspace{.25em} 6 \\
  \end{tabular}

    \uncover<2->{
    % wilcox.test( c(17,20,22,64,170,190,315), c(6,13,14,15,16,18,22,29) ) #= 0.015
    $K_1 = 49.5$ and $K_2 = 6.5$ \\
    $0.009 \le P \le 0.014$
    }
  \end{center}

\end{frame}

%%%%%% %%%%%%%
\subsection{Testing equality of distributions}

%%%%
\begin{frame}{What are the hypotheses?}

  Wilcoxon--Mann--Whitney tests to see if there are \alert{significantly} more comparisons going in one direction or the other than expected \alert{by chance}.

    \vspace{2em}

    \structure{by chance} under $H_0$: the two population distributions are the same

    \vspace{2em}

    \structure{and contrasted to} $H_A$: one population tends to be larger than the other

    \vspace{2em}

    \structure{Key observation:} if the two populations are the same, both samples, combined, are effectively a single, larger sample.

\end{frame}

%%%%%%
\begin{frame}{The Wilcoxon--Mann--Whitney $P$-value}

  Under $H_0$, the two samples are like one big sample.

  \vspace{2em}

  If so, any ordering of the samples is equally likely.

  \vspace{2em}

  \structure{Exercise:} Compute the Wilcoxon--Mann--Whitney $P$-values 
  for the samples $Y_1 = \{1 \}$ and $Y_2 = \{ 2, 3, 4\}$.

  \uncover<2->{
  \begin{center}
  \begin{tabular}{ccccc}
    $Y_1$ & $Y_2$ & $K_1$ & $K_2$ & $U_s$ \\
    1 & 2,3,4 & 0 & 3 & 3 \\
    2 & 1,3,4 & 1 & 2 & 2 \\
    3 & 1,2,4 & 2 & 1 & 2 \\
    4 & 1,2,3 & 3 & 0 & 3 \\
  \end{tabular}
  \vspace{1em}

  $U_s = 3$, and $P = 1/2$.
  \end{center}
  }

\end{frame}


%%%%%%
\begin{frame}{Directional Wilcoxon--Mann--Whitney}

  If the alternative hypothesis is \alert{directional}, \\
    the test statistic should reflect this.

    \vspace{2em}

    \structure{Note that} $K_1$ is larger if the values in sample 1 are larger, \\
    \hspace{2em} and vice versa.

    \vspace{2em}

    \structure{Directional test:}
    \begin{itemize}
      \item If the comparison against the direction of the hypothesis, $P>1/2$.
      \item Otherwise, divide the $P$ value by two.
    \end{itemize}

    \vspace{2em}


    \structure{Example:}  If \\
    $H_A$: population 1 tends to be larger than population 2, 
    
    \vspace{1em}

    \hspace{2em} if $K_1 < K_2$, then $P>1/2$, \\
    \hspace{2em} otherwise, find the $P$ with $U_s = K_1$ and divide by two.

\end{frame}

%%%%%%
\begin{frame}{Example}

  Quiz scores from the back and the front of the class:

  \begin{center}
    \begin{tabular}{l|p{1.5in}}
      \hline
      back & 7 \hspace{.25em} 10 \hspace{.25em} 13 \hspace{.25em} 15 \hspace{.25em} 16 \hspace{.25em} 26 \\
      front & \hspace{.25em} 11 \hspace{.25em} 12 \hspace{.25em} 59 \hspace{.25em} 64 \\
      \hline
    \end{tabular}
  \end{center}
  % W = 8, p-value = 0.4762

    \vspace{2em}

  \uncover<2->{
    Or, ranks:
  \begin{center}
    \begin{tabular}{l|p{1.5in}}
      \hline
      back & 1 \hspace{.25em} 2 \hspace{.25em} 5 \hspace{.25em} 6 \hspace{.25em} 7 \hspace{.25em} 8 \\
      front & \hspace{.25em} 3 \hspace{.25em} 4 \hspace{.25em} 9 \hspace{.25em} 10 \\
      \hline
    \end{tabular}
  \end{center}
  }

\end{frame}

%%%%%%% %%%%%%%%
\subsection{Conditions on Wilcoxon--Mann--Whitney}

%%%%%%
\begin{frame}{Conditions on Wilcoxon--Mann--Whitney}

  \begin{enumerate}
    \item No ties (or not too many)
    \item Independence of observations
    \item Independence of samples
  \end{enumerate}

    \vspace{2em}

    \structure{Note} there are no conditions on distribution.

    \vspace{2em}
   \alert{However,}\\
    $H_0$: the two population distributions are identical.


    \vspace{2em}

    \structure{so,} in principle, $H_0$ could be rejected because one distribution is wider than the other, but not shifted overall.

\end{frame}


%%%%%%
\begin{frame}{A thought experiment}

  Suppose there are two islands: 
  on one, half the birds are big (10cm) and the other half are small (1cm);
  on the other, birds are intermediate: half are 5cm, the other half are 6cm.

  \vspace{2em}

  We do not know this, take random samples from the two islands,
  and compare the sizes on the two islands with a Wilcoxon--Mann--Whitney test.
  \begin{itemize}
    \item If we get a significant $P$-value, is that an error or not?
    \item Is the test appropriate?
    \item Are we likely to get a significant $P$-value?
  \end{itemize}

  \vspace{2em}
  \pause

  (Investigation by simulation.)

\end{frame}

%%%%%%
\begin{frame}{Another thought experiment}

  Now, suppose we visit two other islands:
  on one, half the birds are big (10cm) and the other half are small (1cm);
  on the other, birds are intermediate: half are 8cm, the other half are 9cm.

  \vspace{2em}

  Again, we take random samples from the two islands,
  and compare the sizes on the two islands with a Wilcoxon--Mann--Whitney test.
  \begin{itemize}
    \item If we get a significant $P$-value, is that an error or not?
    \item Is the test appropriate?
    \item Are we likely to get a significant $P$-value?
  \end{itemize}

  \vspace{2em}
  \pause

  (Investigation by simulation.)

\end{frame}

%%%%%%
\begin{frame}{The alternative hypothesis}

  This is why the alternative hypothesis for Wilcoxon--Mann--Whitney is:
  \[  H_A \, : \, \text{( one distribution tends to be larger than the other )} \]
  or, more precisely, if we define
  \begin{align*}
    P_\text{diff} = \Pr & \text{( a random sample from population 1 is larger} \\
      & \qquad \text{than an indpendent sample from population 2 )} , 
  \end{align*}
  then
  \[  H_A \, : \, P_\text{diff} \neq 1/2 .\]

  \vspace{2em}

  This is an issue of \structure{power}:
  if the distributions differ, even substantially,
  but $P_\text{diff}=1/2$,
  then Wilcoxon--Mann--Whitney has \alert{no power}.
  (and power is determined by the alternative hypothesis)

\end{frame}


%%%%%%
\begin{frame}{The perils of heteroscedasticity}

  \structure{Strictly speaking}, the $t$ distribution only applies 
  if the two populations have the \alert{same variances}.

    \vspace{2em}

  The $t$ test we have been using is known as ``Welch's $t$ test'',\\
  which applies approximately to populations with different variances.

    \vspace{2em}

    Wilcoxon--Mann--Whitney and the $t$-test are similar in this regard.

\end{frame}


%%%%% %%%%%%% %%%%% %%%%%%%
\section{Comparison of $t$, WMW, and randomization tests}

%%%%% %%%%%%% 
\subsection{Conditions versus power}

%%%%%%
\begin{frame}{Recall the randomization test}

  \begin{block}{the randomization test}
    \begin{enumerate}
      \item Randomly shuffle the data.
      \item Compute the difference in (shuffled) sample means.
      \item Compare to the observed difference.
    \end{enumerate}
    The $P$-value is the proportion of the shuffled differences that are more extreme than the observed difference.
  \end{block}

    \vspace{2em}
    \pause

    This differs from the Wilcoxon--Mann--Whitney in the choice of \alert{test statistic}.

\end{frame}

%%%%%%
\begin{frame}{Conditions versus power}

  The $t$ test has the highest power of any test (with the same $\alpha$);
  but this only applies if the distributional conditions are satisfied.

    \vspace{2em}

  Randomization tests often have similar power to $t$ tests, and fewer conditions.

    \vspace{2em}

  But, it is easier to compute $t$ statistics, and easier to get \alert{confidence intervals}.

    \vspace{2em}

    If in doubt, it is reasonable to apply more than one, and in the case of disagreement, report uncertainty.


\end{frame}


\section<article>{Summary}
\section<presentation>*{Summary}

\begin{frame}{Summary}
  \begin{enumerate}
    \item Distribution-free tests do not put conditions on the shape of the sampling distributions.
    \item One such is the Wilcoxon--Mann--Whitney test, which can be computed using ranks only.
    \item The Wilcoxon--Mann--Whitney counts the number of comparisons between the samples that go in each direction, 
    \item and compares to a table of $P$-values obtained by randomization.
    \item The Wilcoxon--Mann--Whitney test, like the randomization test, has fewer conditions, but has lower power than the $t$ test if the conditions are satisfied.
  \end{enumerate}
\end{frame}

% homework
\begin{frame}{Homework}
  \begin{center}

  7.10.4

  \vspace{2em}

  7.10.6

  \end{center}
\end{frame}


\end{document}





