% Copyright 2007 by Till Tantau
%
% This file may be distributed and/or modified
%
% 1. under the LaTeX Project Public License and/or
% 2. under the GNU Public License.
%
% See the file doc/licenses/LICENSE for more details.


\lecture[12]{Power and false positives}{lecture-text}

\subtitle{hypothesis testing, and one-sided tests}

\date{5 March 2015}

% pp. 218-(242?)


\begin{document}

\begin{frame}
  \maketitle
\end{frame}


\begin{frame}\frametitle<presentation>{Outline}
  \tableofcontents
\end{frame}

\section{Confidence intervals and $P$-values}


%%%%%
\begin{frame}{Confidence intervals and $P$-values}

    Recall that
  for the $t$-test,
  \[  \text{reject $H_0$ at the $\alpha$ significance level} \]
  is \structure{equivalent to}
  \[  \text{ 0 is not in the $(1-\alpha)$-confidence interval for $\mu_1-\mu_2$ }. \]

  \vspace{2em}

  This is because of \alert{symmetry}: \\
  the distribution of the $t-statistic$ always \structure{looks the same},
  no matter the true value of $\mu_1 - \mu_2$,
  just \structure{shifted}.

\end{frame}

%%%%%
\begin{frame}{Example: }

    Noreprenephrin (NE) concentration (ng/gm) in rat brains:
    \begin{center}
      \begin{tabular}{c|rr}
            & Toluene & Control \\
          \hline
          $n$ & 6 & 5 \\
          $\bar y$ & 541.8 & 444.2 \\
          $s$  & 66.1 & 69.6 \\
          $\SE$ & 27 & 31 \\
     \end{tabular}
   \end{center}


     \begin{align*}
         \SE_{\bar Y_1 - \bar Y_2} &= 41.195 \\
         t_s &= 2.34  \\
         \df &= 8.47 
     \end{align*}
     $P$-value: 0.0454 .


  \vspace{2em}

  Here $t_{0.025} = 2.28$, so an $1-\alpha=0.95$ confidence interval is
  \[  (541.8-444.2) \pm 2.28 \times 41.195 = (3.68,191.52) . \]

\end{frame}

%%%%%
\begin{frame}{$P$-value or CI?}

  Which is ``better''?

  \pause
  \begin{itemize}
      \item They use the same information.
      \item Not all tests have a confidence interval.
      \item But, when we do, it tells us the \emph{range} of reasonable values.
      \item \emph{strength of evidence} \structure{versus} \emph{size of effect}
  \end{itemize}

\end{frame}



\section{Hypothesis testing}

%%%%%
\begin{frame}{Interpretation of $\alpha$}

  What the heck is (the significance level) $\alpha$ again?

  \vspace{2em}
  \pause

  It is the \alert{false positive rate}:

  \vspace{2em}
  \pause

  i.e.\ if we did the experiment many times,\\
  \structure{and there was no real effect} ($H_0$ is true)\\
  how often would we \alert{wrongly} conclude there is an effect?

\end{frame}



%%%%%
\begin{frame}{Music and Marigolds}

    Suppose many researchers run experiments\\
    to test whether marigolds grow taller \\
    when listening to Bach (mean height $\mu_1$) or Mozart (mean height $\mu_2$). 


    \vspace{2em}

    \begin{align*}
        H_0 &: \quad \mu_1 = \mu_2  \\
        H_A &: \quad \mu_1 \neq \mu_2 
    \end{align*}

    \vspace{2em}

    If everyone uses $\alpha=0.05$ then
    \begin{itemize}
        \item 95\% would find no significant effect
        \item 2.5\% would find statistically significant evidence that Mozart is better
        \item 2.5\% would find statistically significant evidence that Bach is better
    \end{itemize}
    \ldots \alert{controversy!}

\end{frame}


%%%%%
\begin{frame}{Are 90\% of all studies false?}

        (No.)

    \vspace{2em}
    \pause

    \begin{quote}
        \small
        Suppose you throw a dart at the Big Chart O' Human Metabolic Pathways and supplement your experimental group with the chemical you hit. Then ten years later you come back and see how many of them died of heart attacks.
        Most chemicals on the Big Chart probably don't prevent heart attacks. Let's say only one in a thousand do. 

    \vspace{1em}
        
        \pause Maybe your study will successfully find that 1/1000. But the 999 inactive chemicals will also throw up about 50 (999 $\times$ 5\%) false positives significant at the 5\% level. Therefore, even if you conduct your study perfectly, and it shows a significant decrease in heart attacks, there's about a 98\% chance it's false.
    \end{quote}
    \figcaption{http://slatestarcodex.com/2013/02/17/90-of-all-claims-about-the-problems-with-medical-studies-are-wrong/}


\end{frame}

%%%%%
\begin{frame}{Interpreting a significant result:}

    \begin{itemize}
        \item What questions are being asked?
        \item What is the size of the effect?
        \item Are the assumptions met?
        \item What is the $P$-value?
    \end{itemize}

\end{frame}

%%%%% %%%%%
\section{Type I and Type II Errors}


%%%%%
\begin{frame}{Significance level}

    The \structure{significance level} $\alpha$ is chosen so
    \[
        \prob \{ \text{significant evidence for $H_A$} | \text{$H_0$ is true} \} = \alpha .
    \]
    This is the probability of a \alert{Type I error}.


    \vspace{2em}

    \begin{tabular}{r|cc}
        & \multicolumn{2}{c}{truth} \\
        & $H_0$ & $H_A$ \\
        \hline
        no evidence for $H_A$ & correct & Type II error \\
        good evidence for $H_A$ & Type I error & correct \\
    \end{tabular}

    \vspace{2em}

    \begin{itemize}
        \item[Type I:] Our significant result is actually due to random noise.
        \item[Type II:] There's something really happening, but we couldn't distinguish it from random noise.
    \end{itemize}

\end{frame}


%%%%%
\begin{frame}{Power and Type II error}

    \begin{block}{}
        \alert{Statistical power} is the probability of \emph{not} making a Type II error when $H_A$ is true,
        i.e.\ \structure{of detecting a true signal}.
    \end{block}
    

    \vspace{2em}

    It depends on the \structure{strength} of the signal,\\
    the sample size, and the experimental setup.

\end{frame}


%%%%%
\begin{frame}{Type I and II and tradeoffs}

    A hierarchy of medical studies:
    \begin{itemize}
        \item Case reports or high-volume scans
        \item Exploratory scans or surveys
        \item Case-control studies
        \item Randomized controlled trials
    \end{itemize}


    \vspace{2em}

    Consider risks and benefits.


\end{frame}



%%%%
\section{One--sided $t$-tests}

\subsection{One versus two sides}


%%%%%
\begin{frame}{Back to the $t$ test}
    
    Maybe we had a \structure{strong directional hypothesis}:\\
    we are throwing away half our power!

\end{frame}

%
\begin{frame}{One or two sides?}

  \begin{description}

    \item[two-sided test:] ``Could the two groups look \alert{this different} if they were actually the same?''

    \item[one-sided test:] ``Could this group look \alert{this much larger} than the other group if they were actually the same?''

  \end{description}

  \vspace{2em}

  \only<1>{
  \structure{More precisely,}
  \begin{description}

    \item[two-sided test:] ``What's the chance that the difference in sample means was at least this large, if the control and treatment populations actually have the same mean?''

    \item[one-sided test:] ``What's the chance that the treatment sample mean is at least this much larger than the control group sample mean,
      if the control and treatment populations actually have the same mean?''

  \end{description}
  }

  \only<2>{
  \structure{More concisely,} with $H_0: \; \mu_1 = \mu_2$:
  \begin{description}

    \item[two-sided test:] $H_A: \; \mu_1 \neq \mu_2$

    \item[one-sided test:] $H_A: \; \mu_1 > \mu_2$

  \end{description}

  \vspace{2em}

  \structure{Note:} can do the test in either direction, replacing "larger" with "smaller".
  }

\end{frame}

%%%
\subsection{Finding a one-sided $P$-value}

\begin{frame}{How to do a one-sided test}

  \begin{center}
  \includegraphicscopyright[width=.8\textwidth]{one-tailed-tests}{Samuels, Whitmer, \& Schaffner}
  \end{center}

  \vspace{-1em}

  \begin{enumerate}
    \item Check if the difference in means is in the right direction. (if not, $P>0.5$).

    \item Compute the $t$ statistic:
      \[
          t_s = \frac{ (\bar y_1 - \bar y_2) - 0}{ \SE_{(\bar Y_1 - \bar Y_2)} }
      \]

    \item Compute the degrees of freedom:
        \[
            df = \frac{ (\SE_1^2 + \SE_2^2)^2 }{ \SE_1^4 / (n_1-1) + \SE_2^4 / (n_2 - 1) }
        \]

    \item Look up the $P$-value. (or, check for significance in Table 4)

  \end{enumerate}


\end{frame}

%%
\subsection{What to watch out for}

%
\begin{frame}{How to cheat}

  \begin{enumerate}
    \item Check which mean is larger.
    \item Do a one-sided test, in that direction.
  \end{enumerate}

  \vspace{2em}

  \structure{Solution:} Have a clear hypothesis, that determines the direction beforehand.

  \vspace{2em}

  \begin{block}{Music \& Marigolds}
    If 100 studies look for an effect that isn't real, 
    how many will ``find'' the effect, with
    \begin{itemize}
      \item[\bf (a)] two-tailed tests
      \item[\bf (b)] one-tailed tests, and a clear prior hypothesis
      \item[\bf (c)] one-tailed tests, cheating
    \end{itemize}
  \end{block}

\end{frame}



\section<article>{Summary}
\section<presentation>*{Summary}

\begin{frame}{Summary}
  \begin{enumerate}
    \item
  \end{enumerate}
\end{frame}

% homework
\begin{frame}{Homework}
  \begin{center}

      7.3.4

    \vspace{2em}

    7.3.5

    \vspace{2em}



  \end{center}
\end{frame}


\end{document}





